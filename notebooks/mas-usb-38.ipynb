{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "89edb5c5936d6fb4e3627c471ed77851",
     "grade": false,
     "grade_id": "cell-ebbb7353c30cd75a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<style type=\"text/css\">\n",
    ".time_spent {\n",
    "    width: 3em;\n",
    "    border-style: none;\n",
    "    background-color: silver;\n",
    "    font-weight: bold;\n",
    "    padding-left: 5px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b0c3bd795ca370d11e3630f41448afac",
     "grade": false,
     "grade_id": "cell-8d9ebeb4ac6f0f1a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Hochschule Bonn-Rhein-Sieg\n",
    "\n",
    "# Neural Networks, WS17\n",
    "\n",
    "# Finals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f8352bd9cf0ae7716adc7e0563ccd946",
     "grade": false,
     "grade_id": "cell-31b0bfc70e903dbb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Instructions\n",
    "\n",
    "* **The examination consist of 51 questions.**\n",
    "* **Questions 1) to 17) are mandatory.**\n",
    "* **From questions 18) to 51) please answer exactly 17.**\n",
    "* **Clearly mark all those answers, which you like to be accounted.**\n",
    "* **If not clearly marked, just the first 17 answers(from 18 to 51 ) will be taken into consideration.**\n",
    "* **All questions are *two points*, so the maximum number of points is 68.**\n",
    "* **Try to be concise.  Good luck!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e146c963438a21e71ea8e1e4f7200c0a",
     "grade": false,
     "grade_id": "cell-cf35c09e0c08de9c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Mandatory Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "29c7fe5e8a3c18dd5cfba418dfee5590",
     "grade": false,
     "grade_id": "cell-d02534c64b13d4da",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    " **Question 1** \n",
    " \n",
    " Give a definition for the term \"artificial neural network\" and mention, how it resembles the human brain!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "868aa380e946425157edf6a6680aadc2",
     "grade": true,
     "grade_id": "cell-e5890132e0a9a986",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "A massively distributed processor, consisting of single processing units that have a natural prospensity of storing experimental knowledge and making it available for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "059186270bbb440aa10a6c21e09b123c",
     "grade": false,
     "grade_id": "cell-9ec99e7fc8c78497",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 2** \n",
    "\n",
    "Define the mathematical model of a neuron, use the appropriate technical terms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eb616f17f4ede51fb680ee9241cf1042",
     "grade": true,
     "grade_id": "cell-502b83531ed1c72b",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "$y = \\sum_{i=0} \\Phi(w*x_i)$ \n",
    "\n",
    "A neuron consists of inputs $x$, synpatic weights $w$, an extra input $w_0$ which is fixed to 1 for the bias, an Adder function, that creates the local field $v$ and a squashing function $\\Phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1ff69aa0731290fe3542f5646bda3d55",
     "grade": false,
     "grade_id": "cell-b204e186ee8fb44d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 3** \n",
    "\n",
    "Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "84a255dc198df26874d57da610b5c3a0",
     "grade": true,
     "grade_id": "cell-c4f466c4c48d7154",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1. Initialize the weights at random or as 0.\n",
    "2. Activate the Perceptron by giving an example.\n",
    "3. Compute the actual output of the neuron.\n",
    "4. Adjust the parameters of there perceptron.\n",
    "5. Continue until convergence is achieved.\n",
    "\n",
    "w = rand\n",
    "\n",
    "y = sum($\\Phi$(w*x))\n",
    "\n",
    "for w_i in w:\n",
    "\n",
    "    w_i = w_i+$\\eta$*e*y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84deb44a849805678462a910579865fb",
     "grade": false,
     "grade_id": "cell-990f0107dbdab711",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 4** \n",
    "\n",
    "Explain classification and regression; what is the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e187eda7c96bfa0c5c6e84d484918db3",
     "grade": true,
     "grade_id": "cell-d7eecdd83ae189ce",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In classification a binary pattern has to be partitioned into the two classes. In regression a line has to be fitted closest to some datapoints. The difference is, that in Classification mthe output is a single class label, while in regression the output is continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "044aa4ff45284d6bfb7ea9535eaee31b",
     "grade": false,
     "grade_id": "cell-98ca8ef036360641",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 5** \n",
    "\n",
    "Write down the SOM learning in pseudo code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "129fbaab9f204e17c4fe6105dee3e688",
     "grade": true,
     "grade_id": "cell-dfe3dec79f4a5ed9",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1. Initialize small random weights.\n",
    "2. Draw the nth sample from the input space.\n",
    "3. Similarity matching: Determine the winning neuron.\n",
    "4. Update the weights of the neuron an the topological neighborhood.\n",
    "5. Repeat steps 2-4 \n",
    "\n",
    "w = random\n",
    "\n",
    "n = example.draw()\n",
    "\n",
    "w_max = get_min(w_i*n)\n",
    "\n",
    "h_n = get_neighborhood(w_max)\n",
    "\n",
    "for w_i in h_n:\n",
    "\n",
    "    w_i = w_i+$\\eta$*h*y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8409773c0a3d2bd0400aa5efa2d3df3e",
     "grade": false,
     "grade_id": "cell-2466b3e1aa271459",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 6** \n",
    "\n",
    "Give the basic idea of an SVM using the correct terminology!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e9bc97893bf3827325653a36a780f9f6",
     "grade": true,
     "grade_id": "cell-c9734ca4e09e5224",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "An SVM is a linear classifier that divides a binary pattern, by a line that maximizes the margin between its line and the respective support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0963aeeb30c6016b560d090b6bc71fa7",
     "grade": false,
     "grade_id": "cell-86029dff861d917d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 7** \n",
    "\n",
    " What role does the method of steepest decent have when learning a network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6bb209e27a320bc673c6e370f10aafc4",
     "grade": true,
     "grade_id": "cell-5058bc5a1561d91d",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The steepest descent can be used to optimize the weights of a network. In steepest descent the error function is a function of the weights. So we determine the direction of the steepest descent on the error surface and go into that direction to minimize the error of the weights on optimize them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a65610855211da8bbf316339b1b94052",
     "grade": false,
     "grade_id": "cell-9926819de0c2095b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 8** \n",
    "\n",
    "Define: a hypothesis $h \\in H$ shatters a dataset $A \\subseteq X \\Leftrightarrow \\ldots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8fa7b9a101036a1eff9fd0322d0966f8",
     "grade": true,
     "grade_id": "cell-437814aba6819134",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    ", if there exists a configuration of $X$, so that $h$ gets zero training error on any dichotomy of the datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df9f8b1639ec299c19e61f8f057371cc",
     "grade": false,
     "grade_id": "cell-ed4aaec65a99e08b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 9** \n",
    "\n",
    "Write down and explain the Widrow-Hoff learning rule!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec2d2a809ec6e07a95630077f4349c73",
     "grade": true,
     "grade_id": "cell-e49642f3ebe05fa0",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The Widrow-Hoff rule is used in error-correction learning and uses the current error and output of the system to determine the new weights.\n",
    "\n",
    "$w(n+1) = w(n)+\\eta \\cdot e(n) \\cdot y(n) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1ebfb3e588a95b1223931bbfcb10b211",
     "grade": false,
     "grade_id": "cell-d6571a8b80a8c4c9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 10** \n",
    "\n",
    "Explain back propagation, use the correct technical terms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cf4374ebca5db10ce01f771bc6bb8f56",
     "grade": true,
     "grade_id": "cell-806c758a5b99b2b0",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Backpropagation is used in Multilayer Perceptrons to give a method of adapting the weights. First the forward phase is run like in a regular feedforward network. Then after the output and thus the error is determined the error is backpropagated from ouput layer through the network. Since we have multiple layers, there is only a desired output of the network for the last layer. To counteract this problem a gradient is calculated for every neuron during the backward pass. The gradient is giving a measure of the contribution of this neuron to the final error. The gradient is then used to update the neurons weights. If the neuron is not part of the output layer, the previous gradients are used to calculate the new gradient instead of using the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fcbc6f56230ddddd68741aa6a739ce56",
     "grade": false,
     "grade_id": "cell-87ad5f3f0297ee1b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 11** \n",
    "\n",
    "When learning using steepest descent, explain the role of the learning rate? What is a danger?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9cc8ff74cb5e95a8235a5725eebf368a",
     "grade": true,
     "grade_id": "cell-232ce8060d0cf7fc",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "If we use steepest descent we use the learning rate to adjust the speed of the convergence to a minimum error. If the learning rate is too small, the learning is going on rather slow. If the rate is high, the error is zigzagging on the error surface towards the minimum. If the learning rate is to high, it might not converge but diverge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a16a6ff3515cd16331d71d80f1fcec6",
     "grade": false,
     "grade_id": "cell-c700e21684d4ac90",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 12** \n",
    "\n",
    "How does a Reduced Boltzman Machine work (main idea)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9d95bf60d717190b4aa780ebd7066b00",
     "grade": true,
     "grade_id": "cell-b3a015c1a1306f3f",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In RBMs there are two states, the free running and the clamped state. During the clamped state, the input neurons are clamped to the output neurons. While the network is clamped the probabilities of the Hidden states to be in a certain state are calculated to determine a probability of the output to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3243d83d92595058c10832da8d064cf",
     "grade": false,
     "grade_id": "cell-b3bbca61dc6d56d0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 13** \n",
    "\n",
    "Define: Echo State Network (ESN), how are they different to FF NNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec070f3b40cdb6bd89707e041824b71c",
     "grade": true,
     "grade_id": "cell-1ba6fee489fff4e4",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In contrast to regular feedforward networks, ESN belongs to the group of Recurrent Neural Networks. It has a regular input layer like the FF, then comes a dynamic reservoir, which is a layer of neurons, where at least one full cycle of connections between the neurons is given. The connections inside this reservoir are not constrained and can thus be any possible connection. This reservoir is randomly initilaized and kept that way. Only the respective connections to the output layer are trained during the learning process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60994d4cd7912778b2e5862898259c96",
     "grade": false,
     "grade_id": "cell-a8f1a0b07faf6ff4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 14** \n",
    "\n",
    "Describe: the structure on an CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b7de256aa9bb15f19423d81a73ddfeec",
     "grade": true,
     "grade_id": "cell-c2c2c3560e83d498",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "A Concolutional neural network has alternating layers of convolution and pooling. The convolutional layer is applying a filter to the input, while the pooling layer sub-samples the input. In some networks this is replaced by strided convolution, which combines these two steps into one. The structure at the end of a CNN is equal to that of a regular feedforward network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55b293b4ed36cf871a30a344a2ba5029",
     "grade": false,
     "grade_id": "cell-b4fed7847cc9c44d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 15** \n",
    "\n",
    "What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e3a41158296775dac00f4478f42184b3",
     "grade": true,
     "grade_id": "cell-8bd704444099264a",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The centers of the clusters, the widhts of the clusters and the weights. \n",
    "In contrast to other NNs the output only depends on the radial distance to the center of the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23320d65a593227847f5f4e809b0d205",
     "grade": false,
     "grade_id": "cell-a6bb6417da7382d5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 16** \n",
    "\n",
    "Describe how learning based on k-nearest neighbors works, use pseudo code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da6a254019730ca407134f258872e2f0",
     "grade": true,
     "grade_id": "cell-af8d309a961f4b24",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1. Get the nearest neighbor of the current x'\n",
    "2. Remove it from L \n",
    "3. Get the class of the current x \n",
    "4. Classify x' as the class that occurs the most often in the neighbors\n",
    "\n",
    "for 1 to K:\n",
    "\n",
    "    L_i = L/x'\n",
    "    \n",
    "    x_nn = min(|x-x'|)\n",
    "    \n",
    "    c = getclassof(x_nn)\n",
    "    \n",
    "    AmountofClasses.add(c)\n",
    "    \n",
    "setclassof(x') = Max(AmountofClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "060ff66a55cf6951a787a3bb2368193c",
     "grade": false,
     "grade_id": "cell-58df839c2685c75d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 17** \n",
    "\n",
    "Explain the Bias Variance Dilemma!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2fd4cfc1c11e0024211009cff4e231f7",
     "grade": true,
     "grade_id": "cell-6766237b1170408f",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "When adapting the parameters of a network we can either have a small bias or a small variance. If we have a small bias the approximation of the network is close to the real one, but the variance between trials is very high. If we have a low variance, the bias can't be minimized and the network has a bigger error between the ap√ºproximation and the real value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d67840bba63cf231fed0e85c92355a46",
     "grade": false,
     "grade_id": "cell-ebb0e894188d7a76",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "## End of Mandatory questions \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b0cf56fe9eb177936cf3425ea291eb6",
     "grade": false,
     "grade_id": "cell-c1d75f09327cdc22",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Please write any 17 questions from below. \n",
    "(Exactly 17, if more then the first 17 will be considered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bcb00851dce11ffb41b5fe69dc7868d2",
     "grade": false,
     "grade_id": "cell-d4adcf9c7ca348e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 18** \n",
    "\n",
    "Give the main properties of a SOM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9a9f2491973fc744a083ec6c4baccbae",
     "grade": true,
     "grade_id": "cell-48093af80ef466fa",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Self-organizing, uses unsupervised learning, no desired output needed, combines competitive learning with topological structuring of the network, adjacent neurons have similar weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c07c30ea752457204be85c94a580db86",
     "grade": false,
     "grade_id": "cell-d64e65e22a00e2f4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 19** --\n",
    "\n",
    "Enumerate all learning rules, which you know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "737f86d66781a257cb4417bd37453ea3",
     "grade": true,
     "grade_id": "cell-cad0ebc08e6081e7",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1. Error-correction learning\n",
    "2. Memory based learning\n",
    "3. Hebbian learning\n",
    "4. Competitive learning\n",
    "5. Boltzman learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e3b409b6dcde8b3692ba64095dc72498",
     "grade": false,
     "grade_id": "cell-09bf599f87e2146f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 20** \n",
    "\n",
    "Define sigmoid functions and give at least two examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "671fe993093c1ddf153fa59a2ff4f7d8",
     "grade": true,
     "grade_id": "cell-674d47f9e71bdac1",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fa90fa2e1fce1620877477fb6aa89c4b",
     "grade": false,
     "grade_id": "cell-f1af8bd68a0db181",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 21** --\n",
    "\n",
    "Architectures of NNs fall into different classes, which?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6b4db4c556d48dc7978fccdf096f5508",
     "grade": true,
     "grade_id": "cell-7d2773f59b577532",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1. Single layer feedforward\n",
    "2. Multi layer feedforward\n",
    "3. Recurrent Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73d753eba87410d4a11385f6505d2971",
     "grade": false,
     "grade_id": "cell-af0d170cacd31460",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 22** --\n",
    "\n",
    "What do we understand by weight sharing? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "36c61b30baf667726662f238191c6eae",
     "grade": true,
     "grade_id": "cell-e2b6e4655fd9818d",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Usually every neuron will have different weights for the connection with the previous layer, weight sharing is a method, by which the same set of weights is used for every neuron to connect it to the previous layer. This reduces the number of network parameters that have to be adejusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eda49d2dea8f59a9fd06213e9e5f3aea",
     "grade": false,
     "grade_id": "cell-070ff805e9155578",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 23** --\n",
    "\n",
    "Write down and explain Hebb's rule! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "26e5394fcafcaa643084131218b939f2",
     "grade": true,
     "grade_id": "cell-53fec20e6c1e82db",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Cells that wire together, fire together. Means that the connection between neurons that are activated synchronously is strengthend. There is also the symmetric Hebb's rule, which overcomes the saturation problems with Hebb's rule, by decreasing the connection strength between asynchronously activated neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1cbd9a41a6696bfb3049c18a114339c5",
     "grade": false,
     "grade_id": "cell-10901bc9e21177fb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 24** \n",
    "\n",
    "Compare pros and cons of RBFs and MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f51e34b1dc4cec4ebdde5ffc42bfb1f6",
     "grade": true,
     "grade_id": "cell-350b1326888808ff",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "RBF: splitted learning, local approximator, global approximation properties, non-linear hidden layer, one hidden layer, linear output layer\n",
    "MLP: global learning, global approximator, global approximation properties, linear hidden layer, one or more hidden layers, non-linear output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6698ec5417444b3d55db30776636cffa",
     "grade": false,
     "grade_id": "cell-f254b3bf35175958",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 25** --\n",
    "\n",
    "What are some principle problems in machine learning? Give explanations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4e5894b2a9b9434f230a50f1cdf79d2c",
     "grade": true,
     "grade_id": "cell-a355b26fc52332e1",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Overfitting: The Network memoroizes the data and is not able to generalize\n",
    "\n",
    "Curse of Dimensionality: The needed Training data increases with the number of dimensions of the data\n",
    "\n",
    "Bias-variance dilemma: explained in Q. 17\n",
    "\n",
    "Enough data for training: related to the curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19638cec3d43a63533d1aa67c7a8afdb",
     "grade": false,
     "grade_id": "cell-4a4191b2349b686c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 26**\n",
    "\n",
    "How to remedy over-fitting? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "04818da9f6e66d7533323e9b01ce9ce5",
     "grade": true,
     "grade_id": "cell-9aceafd0a12c53eb",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Introducing random noise so the network is not able to directly learn the data, but rather with some noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b405e1650527b10d7a63879ee20cb5fd",
     "grade": false,
     "grade_id": "cell-c28cd98981ba35a3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 27** --\n",
    "\n",
    "Give the main idea of Cover's theorem and where / how is it used? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "99ce072cf7dd8d54953eba57564628b7",
     "grade": true,
     "grade_id": "cell-b208ef3ed7dd2484",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Cover's theorem is used in SVMs in the form of Kernel functions. It says that a problem casted into a higher dimensional feature space non-linearly is more probable to be linearly separable than in lower dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54228411b1e7fa507aa5adf309ba87c0",
     "grade": false,
     "grade_id": "cell-9c2a00ab288f0b58",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 28** --\n",
    "\n",
    "Explain the concept of Kernel functions used in SVMs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "75ea7b04241a9b22abce32638f51a6f2",
     "grade": true,
     "grade_id": "cell-c7a944a33501ad74",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Kernel functions in svm transform a problem in a lower dimension into a higher dimension in order to give new view points on the data, that may enable a linear partioning of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "39bd8edcfc87cc2aef8ada60ff872f36",
     "grade": false,
     "grade_id": "cell-395798328a2aaa0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 29** \n",
    "\n",
    "What does the Perceptron Learning Theorem tell us? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "72d1b2f0a810f724ce5f1b6fb9267021",
     "grade": true,
     "grade_id": "cell-f9139e455838f7f5",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "If the binary-pattern is linearily solvable, a perecptron is able to classify all points correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "40fde65f9492974821ae8874fdf8d538",
     "grade": false,
     "grade_id": "cell-5b25070cccfc2224",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 30** --\n",
    "\n",
    "What is three-way data split and how to use if for NN training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "33d9fa84ba7bb218192499688a48ab5a",
     "grade": true,
     "grade_id": "cell-0d41947379696535",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In a three-way data split, the data is spit into three sets, the training set, the validation set and the test set. If different archictectures have to be evaluated, the three-way split helps to choos the architecture of the network. For this purpose all architectures are trained on the training set. The validation set is then used to determine a training error. From the results the best performing architecture is choosen and trained on the training and validation set. The test set is the used to accquire the final error of the choosen architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6fcb2c34e68901fda1eeca31ce4ed58e",
     "grade": false,
     "grade_id": "cell-7343cb3dc2c6c040",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 31** --\n",
    "\n",
    "Explain the behavior of train and test error, if we add more and more training samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "80656baa0c08bad600721196aeb80bee",
     "grade": true,
     "grade_id": "cell-b1ae91e6150ae76e",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "We are not able to calculate the test error of a network since we would need all possible test cases for this. So we can instead approximate the test error by computing a training error on a given training set that contains a subset of all examples. So the more samples we add, the closer the training set gets to containig all examples and thus the trainig error approximates the test error closer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d4309968f4f433ae439b452b1949179f",
     "grade": false,
     "grade_id": "cell-d53296b06f0c9984",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 32** --\n",
    "\n",
    "Define and explain the term local gradient in back-propagation! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7bde7e54ad86f57ccfb45df0df145c50",
     "grade": true,
     "grade_id": "cell-90078dffd69198c9",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "A local gradient is the measure of how much the neuron that the gradient belongs to contributes to the final error. So it can be used to adjust the weights of a neuron in a multilayer perceptron. It depends on the neurons position how this gradient is calculated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "728bc07e05cc9eacd1636da5a4b2df78",
     "grade": false,
     "grade_id": "cell-75531000ef925de6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 33** \n",
    "\n",
    "\n",
    "Reproduce the formulas for training error and test error! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e2faeb3d8c4da61147f78522d9cec103",
     "grade": true,
     "grade_id": "cell-eb6d105a3eefde42",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75a19718dc9876032ae1725418d17429",
     "grade": false,
     "grade_id": "cell-756ef32070873305",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 34** --\n",
    "\n",
    "\n",
    "What is Newtons method in general? How can it be utilized for NNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "325fb08aac33b7d95d466bb5fd5dcab6",
     "grade": true,
     "grade_id": "cell-c735cb6d42ed5504",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Newtons method is used to optimize a function by using the second order tylor expansion on a point, then getting the minimum for that expansion and take it as the next point. In NNs it is used to optimize the weights of the network by finding the weight vector that minimizes the error between output and desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eda5f696ce0f04ff0d73e34458d915b1",
     "grade": false,
     "grade_id": "cell-f21084328bbfe76c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 35**\n",
    "\n",
    "What do we understand by \"momentum\" in context of learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1f244c52eac98bdb492f33eef2bd54aa",
     "grade": true,
     "grade_id": "cell-4339f23a55ef1521",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The momentum is a additional term introduced in the learning rule to accelerate the descent of the error into steady downhill direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19bcf5ea497a6ee1aae0d63775da2fae",
     "grade": false,
     "grade_id": "cell-2f9bb5d16622824c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 36** \n",
    "\n",
    "What is \"normalization\" of inputs? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c33eda5e4280be787169b0c1094172d8",
     "grade": true,
     "grade_id": "cell-8a11da0165c2314a",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Normalization of inputs is the mean removal, the decorrolation and covariance equalization of the data in order to enable a network to have the same learning speed over the whole network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "91c74a78afc6bd49715d940afcc8a913",
     "grade": false,
     "grade_id": "cell-74ed903c3e6582c3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 37** --\n",
    "\n",
    "When designing a feed-forward NN how to determine the correct number of layers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d0eab651df5e3950b041e56a6b2f30ca",
     "grade": true,
     "grade_id": "cell-14e15e4b9e931806",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In order to determine the number of layers, different numbers of layers have to be implemented and tested. The one with the best performance is then chosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "05562e183ed94b0db30cfda9b1db5368",
     "grade": false,
     "grade_id": "cell-70554724ecb8770d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 38**\n",
    "\n",
    "How many training examples are needed for training an NN? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fce43776b263445c5d045cfde4d1c382",
     "grade": true,
     "grade_id": "cell-c248f01fad1aa9a6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "A rule of thumb says that 5-10 the number of parameters that have to be adapted. In general it can't be said, but an upper bound can be given by using the VC-Dimensions of a network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82a6a58b18375e8f74e74f28d7d5ac3c",
     "grade": false,
     "grade_id": "cell-c03a87c5207dcb35",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 39** --\n",
    "\n",
    "Give some examples of families of RBF functions! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2fa39873c6ad09c2a9f789c3c0bfb50d",
     "grade": true,
     "grade_id": "cell-034a98640cd4b760",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "1. Gaussian function\n",
    "2. Multi Quadrics\n",
    "3. Inverse Multiquadrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d05791a4445fa670a745417dcd7a12d8",
     "grade": false,
     "grade_id": "cell-93c61186c0de73e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 40** --\n",
    "\n",
    "Enumerate and explain all variants of minimum complexity Echo State Network (mcESN)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "183385017877a5624db6bb574c42b37c",
     "grade": true,
     "grade_id": "cell-73c6da16e08d6c9f",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Delay line reservoir: The dynamic reservoir has a time-delay connection running from one neuron to the next without feedback.\n",
    "\n",
    "DLR with feedback: The same as the Delay line, only this time each neuron is connected over a feedback to the previous one.\n",
    "\n",
    "Single Cycle reservoir: The same as Delay line, only the last neuron is connected to the first one of the delay line via a feedback connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1dd1baec1655b9bde2fee7d52c4a68d2",
     "grade": false,
     "grade_id": "cell-97c2ac4e99a30177",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 41** \n",
    "\n",
    "Give an easy example  for a non-linear single feedback neuron systems which shows very complex behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b7af92260c4ad8bb205c8f1b885afa04",
     "grade": true,
     "grade_id": "cell-b0f8504a59a45df2",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e11a45bac53ad966889ca51e58533aae",
     "grade": false,
     "grade_id": "cell-d9db8c533457af9b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 42** \n",
    "\n",
    "Why and how are recurrent NNs unfolded in back-propagation-through-time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b77e12153add57867f0d51071ecd0b48",
     "grade": true,
     "grade_id": "cell-6949bbeea4827fcb",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "17d95cbdc4650a068f8024be0db16f2e",
     "grade": false,
     "grade_id": "cell-fead41e0da7815e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 43** \n",
    "\n",
    "What is a bifurcation and how does this relate to NNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "02b1b90ec51331e8b140c30418b0ceff",
     "grade": true,
     "grade_id": "cell-17e083fa09be8cde",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "if using gradient descent a function should converge to a minimum, if we have a birfurcation, the function instead flips between two minimums. For every new bifurcation the minimum again splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "526b95e97391cb4836e6f507ba743c78",
     "grade": false,
     "grade_id": "cell-4d09675f1749b906",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 44** \n",
    "\n",
    "Describe two cases, why spheres in higher dimensions behave counter intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fbc86dcefcd5e053dae9969c5f364d30",
     "grade": true,
     "grade_id": "cell-c7c39b3d56008b8e",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In higher dimensions, most of a spheres mass is lying in the shell of the sphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "620759e3b1108ade43a9924c66ae2dc8",
     "grade": false,
     "grade_id": "cell-d6e2fbb2ee92ec17",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 45** \n",
    "\n",
    "What general underlying problem is solved when fitting models to data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da659b788e9dfd608ba62c0593d3be60",
     "grade": true,
     "grade_id": "cell-9f26c1b453437a21",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "70033803fb7dde719de72b543efd21b1",
     "grade": false,
     "grade_id": "cell-4d2a6a819abe5f86",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 46** --\n",
    "\n",
    "What are Gabor functions in the context of CNNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3c76e053e3e4e09bc43207bc1bde12fc",
     "grade": true,
     "grade_id": "cell-ce978f320a49587c",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Gabor functions in general are directed edge filters. In CNNs different Kernels are learned in the convolutional layers of a network. These learned kernels are very similar to the gabor filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8eb80c42cf4832b892081b2b9d996089",
     "grade": false,
     "grade_id": "cell-cf10859efadd26e1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 47** --\n",
    "\n",
    "Explain the term \"k-fold cross validation\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3ea44cb7e243f25c0e7d933f47c058cb",
     "grade": true,
     "grade_id": "cell-03e40449ec4e23fd",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In K-fold-cross validation the training set is split into K equal sized parts. While one of the parts is used for testing the others are used for training. This method is used to overcome the lack of training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "124a27d4b36f549759dc9bab26797e31",
     "grade": false,
     "grade_id": "cell-afc5bd9c687e4930",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 48** \n",
    "\n",
    "Give two robotical problems (at least) which may be solved using ESNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "65486748ba14d2aced98fd291773f1e7",
     "grade": true,
     "grade_id": "cell-00d969f8d1de1b32",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "tone generator, sequence modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "39108e410d2884dc12e03768f9558c7b",
     "grade": false,
     "grade_id": "cell-c2a38b7e1044e164",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 49** \n",
    "\n",
    "Give samples for problems with can be solved using SOMs and explain how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "15d237ac4e1e3ce0f9627237c513539e",
     "grade": true,
     "grade_id": "cell-a395bbc452595975",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Traveling salesman problem: The solution to this problem is a cirle that passes through all cities to be visited.  If the neurons of the map layer are ordered as a circle, the network can approximate the shortest cycle to visit all cities, by shifting the neurons weights according to the cities positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d5654379aad989c4641d4819b72afd42",
     "grade": false,
     "grade_id": "cell-bd855ef8c19bc45a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 50** \n",
    "\n",
    "Explain the central idea behind the Gauss-Newton method and where can it be applied in NN learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d7c9e112cd21649b40cdcbd842f2d792",
     "grade": true,
     "grade_id": "cell-d4b8c2904229772d",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "de737871e047972598b9525b762b92fe",
     "grade": false,
     "grade_id": "cell-80dc5572a9ae2736",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Question 51** --\n",
    "\n",
    "Define max-pooling and the term ReLU in context of CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ca64a5be7e809bed468b29afc4dfdebc",
     "grade": true,
     "grade_id": "cell-ed0938fa081a4cfd",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Max-pooling is a method used in CNN in the pooling layers, where a small window, called kernel is slided over the input and for every position of the kernel, the maximum value is choosen. Thus the size of the data is reduced by taking only the maxmimum value of each kernel window position. \n",
    "ReLU is an activation function used in CNNs. The function is diverentiable from 0 onwards and doesn't run into the Vanishing gradient problem like the sigmoid and is thus applicable to deeper networks. \n",
    "\n",
    "y = max(0,x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
